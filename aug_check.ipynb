{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.processor import AudioProcessor\n",
    "from utils.dataset_utils import get_concat_dataset\n",
    "from utils.config_loader import load_config\n",
    "from torchvision.transforms import Compose\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(\"./config/augment_test.yaml\")\n",
    "log_mel_conf = config.data.audio.log_mel_conf\n",
    "ori_datasets = get_concat_dataset(\n",
    "    [\"\"], \"train\"\n",
    ")\n",
    "ori_processor = AudioProcessor(None, None, log_mel_conf, None, None, None)\n",
    "ori_func = Compose([ori_processor.raw_to_logmelspect,ori_processor.output_transpose])\n",
    "ori_datasets.set_transform(ori_func)\n",
    "train_datasets = get_concat_dataset(\n",
    "    [\"\"], \"train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = None\n",
    "\n",
    "# speed change augmentation\n",
    "# speed_aug_conf = config.data.audio.speed_aug_conf\n",
    "speed_aug_conf = None\n",
    "\n",
    "# time or frequency masking (something to 0)\n",
    "# spec_aug_conf = config.data.audio.spec_aug_conf\n",
    "spec_aug_conf = None\n",
    "\n",
    "# specific time copy and random point override\n",
    "# spec_sub_conf = config.data.audio.spec_sub_conf\n",
    "spec_sub_conf = None\n",
    "\n",
    "# random sequence time section delete(trim)\n",
    "spec_trim_conf = config.data.audio.spec_trim_conf\n",
    "# spec_trim_conf = None\n",
    "\n",
    "audio_processor = AudioProcessor(\n",
    "    speed_aug_conf,\n",
    "    normalize,\n",
    "    log_mel_conf,\n",
    "    spec_aug_conf,\n",
    "    spec_sub_conf,\n",
    "    spec_trim_conf,\n",
    ")\n",
    "training_get_func = Compose(\n",
    "    [\n",
    "        audio_processor.raw_audio_preprocess,\n",
    "        audio_processor.raw_to_logmelspect,\n",
    "        audio_processor.spectrogram_preprocess,\n",
    "        audio_processor.output_transpose,\n",
    "    ]\n",
    ")\n",
    "train_datasets.set_transform(training_get_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = random.randint(0, len(train_datasets)-1)\n",
    "fig, ax = plt.subplots()\n",
    "img = librosa.display.specshow(ori_datasets[320000][\"input_values\"].T.numpy(), x_axis='time', y_axis='linear', ax=ax)\n",
    "ax.set(title='ORIGINAL!!!!!')\n",
    "fig.colorbar(img, ax=ax, format=\"%+2.f dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = random.randint(0, len(train_datasets)-1)\n",
    "fig, ax = plt.subplots()\n",
    "temp = train_datasets[320000][\"input_values\"].T.numpy()\n",
    "img = librosa.display.specshow(temp, x_axis='time', y_axis='linear', ax=ax)\n",
    "ax.set(title='AUG FINAL!!!!')\n",
    "fig.colorbar(img, ax=ax, format=\"%+2.f dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "win_length = int(np.ceil(log_mel_conf.sample_rate * log_mel_conf.window_size_sec))\n",
    "n_fft = win_length\n",
    "hop_length = int(log_mel_conf.sample_rate * log_mel_conf.window_stride_sec)\n",
    "res = librosa.feature.inverse.mel_to_audio(temp, \n",
    "                                           sr=log_mel_conf.sample_rate, \n",
    "                                           n_fft=n_fft, \n",
    "                                           hop_length=hop_length, \n",
    "                                           win_length=win_length, \n",
    "                                           window='hamming',\n",
    "                                           center=True, \n",
    "                                           pad_mode='reflect', \n",
    "                                           power=2.0, \n",
    "                                           n_iter=32)\n",
    "# ori = librosa.feature.inverse.mel_to_audio(ori_datasets[320000][\"input_values\"].T.numpy(), \n",
    "#                                            sr=log_mel_conf.sample_rate, \n",
    "#                                            n_fft=n_fft, \n",
    "#                                            hop_length=hop_length, \n",
    "#                                            win_length=win_length, \n",
    "#                                            window='hamming',\n",
    "#                                            center=True, \n",
    "#                                            pad_mode='reflect', \n",
    "#                                            power=2.0, \n",
    "#                                            n_iter=32)\n",
    "import soundfile as sf\n",
    "sf.write(\"./test1.wav\", res, log_mel_conf.sample_rate)\n",
    "# sf.write(\"./ori1.wav\", ori, log_mel_conf.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write(\"./ori_ori.wav\",np.array(ori_datasets[320000][\"input_values\"]), 16000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".streaming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
